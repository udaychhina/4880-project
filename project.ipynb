{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The data\n",
    "\n",
    "The data is a list of article metadata from NYT for the month of January through\n",
    "the years 2013 to 2024. The data is in JSON format. \n",
    "\n",
    "Our goal is to import all the saved data and create a pandas DataFrame with it.\n",
    "This will let us analyze the data and answer questions like:\n",
    "\n",
    "- Trends in article topics over the last 10 years\n",
    "- Most popular authors\n",
    "- Most popular sections\n",
    "- Most popular keywords\n",
    "- Most popular articles\n",
    "- and so on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "config = dotenv_values(\".env\")\n",
    "\n",
    "API_KEY = config['API_KEY']\n",
    "\n",
    "def get_nyt_articles(year, month):\n",
    "    url = f'https://api.nytimes.com/svc/archive/v1/{year}/{month}.json?api-key={API_KEY}'\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    # return only the articles. The response object contains metadata as well.\n",
    "    return response.json()['response']['docs']\n",
    "\n",
    "def build_nyt_archive():\n",
    "    articles = []\n",
    "    month = 1\n",
    "    for year in range(2014, 2025):\n",
    "        articles.extend(get_nyt_articles(year, month))\n",
    "        print(f'Fetched {len(articles)} articles total.')\n",
    "        time.sleep(20)\n",
    "    return articles\n",
    "\n",
    "def save_nyt_archive(articles):\n",
    "    # check if the data folder exists, if not, create it\n",
    "    if not os.path.exists('data'):\n",
    "        os.makedirs('data')\n",
    "    with open('data/nyt_archive_2014_2024_jan.json', 'w') as f:\n",
    "        json.dump(articles, f)\n",
    "\n",
    "articles = build_nyt_archive()\n",
    "save_nyt_archive(articles)\n",
    "print('NYT archive saved to nyt_archive_2013_2023_jan.json')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57364\n",
      "{'abstract': 'Other than the national championship game, the Rose Bowl offers the most anticipated matchup of the season, but the Capital One Bowl and Fiesta Bowl should also be intriguing.', 'web_url': 'https://www.nytimes.com/2014/01/01/sports/ncaafootball/new-years-day-bowl-games.html', 'snippet': 'Other than the national championship game, the Rose Bowl offers the most anticipated matchup of the season, but the Capital One Bowl and Fiesta Bowl should also be intriguing.', 'lead_paragraph': 'ROSE BOWL', 'print_section': 'B', 'print_page': '10', 'source': 'The New York Times', 'multimedia': [{'rank': 0, 'subtype': 'xlarge', 'caption': None, 'credit': None, 'type': 'image', 'url': 'images/2014/01/01/sports/Y-games/Y-games-articleLarge.jpg', 'height': 318, 'width': 600, 'subType': 'xlarge', 'crop_name': 'articleLarge', 'legacy': {'xlarge': 'images/2014/01/01/sports/Y-games/Y-games-articleLarge.jpg', 'xlargewidth': 600, 'xlargeheight': 318}}, {'rank': 0, 'subtype': 'jumbo', 'caption': None, 'credit': None, 'type': 'image', 'url': 'images/2014/01/01/sports/Y-games/Y-games-jumbo.jpg', 'height': 542, 'width': 1024, 'subType': 'jumbo', 'crop_name': 'jumbo', 'legacy': {}}, {'rank': 0, 'subtype': 'superJumbo', 'caption': None, 'credit': None, 'type': 'image', 'url': 'images/2014/01/01/sports/Y-games/Y-games-superJumbo.jpg', 'height': 1085, 'width': 2048, 'subType': 'superJumbo', 'crop_name': 'superJumbo', 'legacy': {}}, {'rank': 0, 'subtype': 'thumbnail', 'caption': None, 'credit': None, 'type': 'image', 'url': 'images/2014/01/01/sports/Y-games/Y-games-thumbStandard.jpg', 'height': 75, 'width': 75, 'subType': 'thumbnail', 'crop_name': 'thumbStandard', 'legacy': {'thumbnail': 'images/2014/01/01/sports/Y-games/Y-games-thumbStandard.jpg', 'thumbnailwidth': 75, 'thumbnailheight': 75}}, {'rank': 0, 'subtype': 'thumbLarge', 'caption': None, 'credit': None, 'type': 'image', 'url': 'images/2014/01/01/sports/Y-games/Y-games-thumbLarge.jpg', 'height': 150, 'width': 150, 'subType': 'thumbLarge', 'crop_name': 'thumbLarge', 'legacy': {}}], 'headline': {'main': 'Bowl Games to Watch on New Year’s Day', 'kicker': None, 'content_kicker': None, 'print_headline': ' Bowl Games to Watch on New Year&#8217;s Day', 'name': None, 'seo': None, 'sub': None}, 'keywords': [{'name': 'persons', 'value': 'Bierman, Fred', 'rank': 1, 'major': 'N'}, {'name': 'subject', 'value': 'Rose Bowl (Football Game)', 'rank': 2, 'major': 'N'}, {'name': 'subject', 'value': 'Football (College)', 'rank': 3, 'major': 'N'}, {'name': 'organizations', 'value': 'Stanford University', 'rank': 4, 'major': 'N'}, {'name': 'organizations', 'value': 'Michigan State University', 'rank': 5, 'major': 'N'}, {'name': 'subject', 'value': 'Fiesta Bowl', 'rank': 6, 'major': 'N'}, {'name': 'organizations', 'value': 'University of South Carolina', 'rank': 7, 'major': 'N'}, {'name': 'organizations', 'value': 'University of Wisconsin-Madison', 'rank': 8, 'major': 'N'}, {'name': 'organizations', 'value': 'Baylor University', 'rank': 9, 'major': 'N'}, {'name': 'organizations', 'value': 'University of Central Florida', 'rank': 10, 'major': 'N'}], 'pub_date': '2014-01-01T00:00:45+0000', 'document_type': 'article', 'news_desk': 'Sports', 'section_name': 'Sports', 'subsection_name': 'College Football', 'byline': {'original': 'By Fred Bierman', 'person': [{'firstname': 'Fred', 'middlename': None, 'lastname': 'Bierman', 'qualifier': None, 'title': None, 'role': 'reported', 'organization': '', 'rank': 1}], 'organization': None}, 'type_of_material': 'News', '_id': 'nyt://article/b56938ec-95f0-5303-99ff-66542cbe724f', 'word_count': 845, 'uri': 'nyt://article/b56938ec-95f0-5303-99ff-66542cbe724f'}\n"
     ]
    }
   ],
   "source": [
    "def load_json():\n",
    "    with open('data/nyt_archive_2014_2024_jan.json', 'r') as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "articles = load_json()\n",
    "print(len(articles))\n",
    "print(articles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['abstract', 'web_url', 'snippet', 'lead_paragraph', 'print_section', 'print_page', 'source', 'multimedia', 'headline', 'keywords', 'pub_date', 'document_type', 'news_desk', 'section_name', 'subsection_name', 'byline', 'type_of_material', '_id', 'word_count', 'uri'])\n",
      "dict_keys(['main', 'kicker', 'content_kicker', 'print_headline', 'name', 'seo', 'sub'])\n",
      "dict_keys(['name', 'value', 'rank', 'major'])\n",
      "5\n",
      "[{'name': 'persons', 'value': 'Bierman, Fred', 'rank': 1, 'major': 'N'}, {'name': 'subject', 'value': 'Rose Bowl (Football Game)', 'rank': 2, 'major': 'N'}, {'name': 'subject', 'value': 'Football (College)', 'rank': 3, 'major': 'N'}, {'name': 'organizations', 'value': 'Stanford University', 'rank': 4, 'major': 'N'}, {'name': 'organizations', 'value': 'Michigan State University', 'rank': 5, 'major': 'N'}, {'name': 'subject', 'value': 'Fiesta Bowl', 'rank': 6, 'major': 'N'}, {'name': 'organizations', 'value': 'University of South Carolina', 'rank': 7, 'major': 'N'}, {'name': 'organizations', 'value': 'University of Wisconsin-Madison', 'rank': 8, 'major': 'N'}, {'name': 'organizations', 'value': 'Baylor University', 'rank': 9, 'major': 'N'}, {'name': 'organizations', 'value': 'University of Central Florida', 'rank': 10, 'major': 'N'}]\n",
      "{'main': 'Bowl Games to Watch on New Year’s Day', 'kicker': None, 'content_kicker': None, 'print_headline': ' Bowl Games to Watch on New Year&#8217;s Day', 'name': None, 'seo': None, 'sub': None}\n",
      "{'original': 'By Fred Bierman', 'person': [{'firstname': 'Fred', 'middlename': None, 'lastname': 'Bierman', 'qualifier': None, 'title': None, 'role': 'reported', 'organization': '', 'rank': 1}], 'organization': None}\n"
     ]
    }
   ],
   "source": [
    "# Exploration\n",
    "\n",
    "# Each article is a dictionary with multiple keys. Some of the values are\n",
    "# dictionaries themselves. For example, the 'headline' key has a dictionary\n",
    "# as its value. The 'keywords' key has a list of dictionaries as its value.\n",
    "\n",
    "# keys of the articles dictionary\n",
    "print(articles[0].keys())\n",
    "\n",
    "# keys of the headline dictionary\n",
    "print(articles[0]['headline'].keys())\n",
    "\n",
    "# keys of the first keyword dictionary\n",
    "print(articles[0]['keywords'][0].keys())\n",
    "\n",
    "# multimedia is a list of dictionaries for the multimedia content of the article\n",
    "# count of the multimedia content of the first article\n",
    "print(len(articles[0]['multimedia']))\n",
    "\n",
    "# the data I think we should keep from the articles dictionary is:\n",
    "# abstract, byline (Author Name), document_type, headline, keywords, news_desk, section_name, word_count, \n",
    "\n",
    "# print the data in the keywords field\n",
    "print(articles[0]['keywords'])\n",
    "\n",
    "# print the data in the headline field\n",
    "print(articles[0]['headline'])\n",
    "\n",
    "# print the data in the byline field\n",
    "print(articles[0]['byline'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating dataframes\n",
    "\n",
    "We will create a pandas DataFrame from the data based on the fields we've\n",
    "decided to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           headline                  pub_date  \\\n",
      "0             Bowl Games to Watch on New Year’s Day  2014-01-01T00:00:45+0000   \n",
      "1       New Year’s Eve, Stuck in a Church in Bangui  2014-01-01T00:00:48+0000   \n",
      "2  House Prices Rise Again, but the Pace Could Slow  2014-01-01T00:01:56+0000   \n",
      "3    Jaywalking Rules and Habits: L.A. vs. New York  2014-01-01T00:22:05+0000   \n",
      "4                              Drawn Back Into Iraq  2014-01-01T00:22:53+0000   \n",
      "\n",
      "  document_type  word_count news_desk  section_name type_of_material  \\\n",
      "0       article         845    Sports        Sports             News   \n",
      "1       article         449                   Blogs             News   \n",
      "2       article         906  Business  Business Day             News   \n",
      "3       article         423   Letters       Opinion           Letter   \n",
      "4       article         220   Letters       Opinion           Letter   \n",
      "\n",
      "   multimedia_count             byline        persons  \\\n",
      "0                 5    By Fred Bierman  Bierman, Fred   \n",
      "1                 0  By Heather Murphy            NaN   \n",
      "2                 5    By Annie Lowrey  Lowrey, Annie   \n",
      "3                 5                               NaN   \n",
      "4                 0                     Obama, Barack   \n",
      "\n",
      "                                             subject  \\\n",
      "0  Rose Bowl (Football Game), Football (College),...   \n",
      "1                                                NaN   \n",
      "2  Real Estate and Housing (Residential), United ...   \n",
      "3                                         Jaywalking   \n",
      "4  United States Defense and Military Forces, Ira...   \n",
      "\n",
      "                                       organizations  \\\n",
      "0  Stanford University, Michigan State University...   \n",
      "1                                             Seleka   \n",
      "2                                                NaN   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                          glocations creative_works  \n",
      "0                                                NaN            NaN  \n",
      "1  AFRICA, Bangui (Central African Republic), Cen...            NaN  \n",
      "2                                                NaN            NaN  \n",
      "3                 Los Angeles (Calif), New York City            NaN  \n",
      "4                                               Iraq            NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def extract_keywords_dynamic(article):\n",
    "    \"\"\"Extracts keywords and groups them dynamically by their 'name'.\"\"\"\n",
    "    keyword_dict = {}\n",
    "\n",
    "    for keyword in article.get('keywords', []):\n",
    "        keyword_type = keyword['name']\n",
    "        keyword_value = keyword['value']\n",
    "\n",
    "        if keyword_type not in keyword_dict:\n",
    "            keyword_dict[keyword_type] = []\n",
    "\n",
    "        keyword_dict[keyword_type].append(keyword_value)\n",
    "\n",
    "    for key in keyword_dict:\n",
    "        keyword_dict[key] = ', '.join(keyword_dict[key])\n",
    "\n",
    "    return keyword_dict\n",
    "\n",
    "articles_data = []\n",
    "for article in articles:\n",
    "    article_data = {\n",
    "        'headline': article['headline']['main'],\n",
    "        'pub_date': article['pub_date'],\n",
    "        'document_type': article['document_type'],\n",
    "        'word_count': article.get('word_count', 0),\n",
    "        'news_desk': article.get('news_desk'),\n",
    "        'section_name': article.get('section_name'),\n",
    "        'type_of_material': article.get('type_of_material'),\n",
    "        'multimedia_count': len(article.get('multimedia', [])),\n",
    "        'byline': article.get('byline', {}).get('original', np.nan),\n",
    "    }\n",
    "    article_data.update(extract_keywords_dynamic(article))\n",
    "\n",
    "    articles_data.append(article_data)\n",
    "\n",
    "df = pd.DataFrame(articles_data)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data\n",
    "\n",
    "For this next part we are going clean some of the data columns. Everything\n",
    "after multimedia counts is a keyword. We need to make sure we are able to\n",
    "separate them into their own columns so that it's a little clearer to see what\n",
    "is going on. Right now the names of the keywords are the column headers and\n",
    "the values are in the rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the columns of the dataframe\n",
    "#print(df.columns)\n",
    "\n",
    "# let's find out unique values in the subject column and the count.\n",
    "# print(df['subject'].value_counts())\n",
    "\n",
    "# right now, the subject column groups each of the subjects into a single\n",
    "# string, separated by commas. Let's split them into separate columns. We will\n",
    "# name them subject_1, subject_2, subject_3, and so on. This will depend on\n",
    "# the number of subjects for each article. Some have only one subject, while\n",
    "# others have multiple subjects.\n",
    "\n",
    "# print(df['subject'].head())\n",
    "# for i in range(20):\n",
    "#     print(df.iloc[i]['subject'])\n",
    "# print(df.iloc[0]['subject'])\n",
    "# get the maximum number of subjects for an article\n",
    "# max_subjects = df['subject'].str.split(', ')\n",
    "\n",
    "# split_data = max_subjects.dropna().apply(lambda x: [item.strip() for item in x[0].split(',')])\n",
    "# print(split_data)\n",
    "\n",
    "# max_subjects = split_data.apply(len).max()\n",
    "\n",
    "\n",
    "# print(max_subjects)\n",
    "\n",
    "# print(type(max_subjects))\n",
    "# # create a new dataframe with the subject columns\n",
    "# df_subjects = df['subject'].str.split(',', expand=True)\n",
    "\n",
    "# # rename the columns\n",
    "# df_subjects.columns = [f'subject_{i+1}' for i in range(max_subjects)]\n",
    "\n",
    "# # combine the two dataframes\n",
    "# df = pd.concat([df, df_subjects], axis=1)\n",
    "\n",
    "# # drop the original subject column\n",
    "# df = df.drop('subject', axis=1)\n",
    "\n",
    "# print(df.head())\n",
    "\n",
    "# get the count of subjects for each article\n",
    "df['subject_count'] = df['subject'].apply(lambda x: len(x.split(',')) if pd.notna(x) else 0)\n",
    "\n",
    "# get the row with the maximum number of subjects\n",
    "max_subject_row = df['subject_count'].idxmax()\n",
    "\n",
    "# count for the maximum number of subjects\n",
    "# print(df['subject_count'].max())\n",
    "\n",
    "# print the row with the maximum number of subjects\n",
    "\n",
    "# print(df['subject_count'].head())\n",
    "\n",
    "subjects_split = df['subject'].str.split(',', expand=True)\n",
    "\n",
    "subjects_split.columns = [f\"subject_{i+1}\" for i in range(subjects_split.shape[1])]\n",
    "\n",
    "# df_with_subjects.to_csv('data/nyt_archive_2014_2024_jan.csv', index=False)\n",
    "\n",
    "# We will have to do the same thing with the organizations and glocations\n",
    "# columns.\n",
    "\n",
    "# get the count of organizations for each article\n",
    "df['organizations_count'] = df['organizations'].apply(lambda x: len(x.split(',')) if pd.notna(x) else 0)\n",
    "\n",
    "# get the row with the maximum number of organizations\n",
    "max_organizations_row = df['organizations_count'].idxmax()\n",
    "\n",
    "\n",
    "\n",
    "organizations_split = df['organizations'].str.split(',', expand=True)\n",
    "\n",
    "organizations_split.columns = [f\"organization_{i+1}\" for i in range(organizations_split.shape[1])]\n",
    "# df_with_organizations = pd.concat([df, organizations_split], axis=1)\n",
    "\n",
    "# get the count of glocations for each article\n",
    "df['glocations_count'] = df['glocations'].apply(lambda x: len(x.split(',')) if pd.notna(x) else 0)\n",
    "\n",
    "# get the row with the maximum number of glocations\n",
    "max_glocations_row = df['glocations_count'].idxmax()\n",
    "\n",
    "\n",
    "\n",
    "glocations_split = df['glocations'].str.split(',', expand=True)\n",
    "\n",
    "glocations_split.columns = [f\"glocation_{i+1}\" for i in range(glocations_split.shape[1])]\n",
    "\n",
    "\n",
    "df_separated = pd.concat([df, subjects_split, organizations_split, glocations_split], axis=1)\n",
    "\n",
    "df_separated.to_csv('data/nyt_archive_2014_2024_jan.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date cleaning\n",
    "\n",
    "The date column is a string. We can use regex to extract the year, month, and\n",
    "day from the date and put them in their own columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date cleaning\n",
    "# convert the pub_date column to a datetime object\n",
    "df_separated['pub_date'] = pd.to_datetime(df_separated['pub_date'])\n",
    "\n",
    "# get the year, month, and day from the pub_date column\n",
    "df_separated['year'] = df_separated['pub_date'].dt.year\n",
    "df_separated['month'] = df_separated['pub_date'].dt.month\n",
    "df_separated['day'] = df_separated['pub_date'].dt.day\n",
    "\n",
    "# drop the pub_date column\n",
    "df_separated = df_separated.drop('pub_date', axis=1)\n",
    "\n",
    "# save the cleaned data to a new CSV file\n",
    "df_separated.to_csv('data/nyt_archive_2014_2024_jan_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author cleaning\n",
    "\n",
    "The author column is a string. We can use regex to extract the author name\n",
    "from the author column and put it in its own column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            6278\n",
      "The New York Times                          1934\n",
      "By The New York Times                        708\n",
      "By The Editorial Board                       531\n",
      "By The Learning Network                      446\n",
      "                                            ... \n",
      "By Lauren Hard                                 1\n",
      "By Jeremy D. Goodwin                           1\n",
      "By Robert W. Goldfarb                          1\n",
      "By Emily Cochrane and Michael S. Schmidt       1\n",
      "By Claire Moses and Orlando Mayorquin          1\n",
      "Name: byline, Length: 10760, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# author cleaning\n",
    "\n",
    "# get the unique values in the byline column\n",
    "print(df_separated['byline'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      6278\n",
      "The New York Times                    2642\n",
      "The Editorial Board                    531\n",
      "The Learning Network                   446\n",
      "Paul Krugman                           306\n",
      "                                      ... \n",
      "Maryanne Garbowsky                       1\n",
      "Niraj Chokshi and Daniel Victor          1\n",
      "Jordan Rau                               1\n",
      "Amir Ahmadi Arian                        1\n",
      "Claire Moses and Orlando Mayorquin       1\n",
      "Name: byline, Length: 10709, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# remove the 'By ' prefix from the byline column\n",
    "df_separated['byline'] = df_separated['byline'].str.replace('By ', '')\n",
    "\n",
    "# get unique values in the byline column\n",
    "print(df_separated['byline'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename byline column to author\n",
    "df_separated = df_separated.rename(columns={'byline': 'author'})\n",
    "\n",
    "# save the cleaned data to a new CSV file\n",
    "df_separated.to_csv('data/nyt_archive_2014_2024_jan_cleaned.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some articles have multiple authors and some have none. Some have only one\n",
    "# author. The multiple authors are split by commas and the word 'and'. We can\n",
    "# split the authors into separate columns. We will name them author_1,\n",
    "# author_2,\n",
    "# author_3, and so on. This will depend on the number of authors for each \n",
    "# article. \n",
    "\n",
    "# we can do this similar to how we split the subjects, organizations, and\n",
    "# glocations columns.\n",
    "\n",
    "# get the count of authors for each article\n",
    "df_separated['author_count'] = df_separated['author'].apply(lambda x: len(x.split(', | and')) if pd.notna(x) else 0)\n",
    "\n",
    "# get the row with the maximum number of authors\n",
    "max_author_row = df_separated['author_count'].idxmax()\n",
    "\n",
    "# split the authors into separate columns\n",
    "authors_split = df_separated['author'].str.split(', | and', expand=True)\n",
    "\n",
    "authors_split.columns = [f\"author_{i+1}\" for i in range(authors_split.shape[1])]\n",
    "\n",
    "df_separated = pd.concat([df_separated, authors_split], axis=1)\n",
    "\n",
    "# save the cleaned data to a new CSV file\n",
    "df_separated.to_csv('data/nyt_archive_2014_2024_jan_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
